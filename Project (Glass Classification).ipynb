{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Glass Classification\n",
    "\n",
    "### Using K - Nearest Neighbor Algorithm\n",
    "### Computer Science Engeneering\n",
    "### June 7 2019 \n",
    "### Team P. Sudarshan Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 1: Introduction to the Data Set\n",
    "\n",
    "### Instructions\n",
    "\n",
    "        ● Read glass.data into a dataframe.Read in the file using pandas.read_csv() \n",
    "        \n",
    "        ● Determine which columns are numeric and can be used as features and which column is\n",
    "        the target column and which columns can be converted into numeric.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.51665</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.76</td>\n",
       "      <td>72.48</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.51707</td>\n",
       "      <td>13.48</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.71</td>\n",
       "      <td>72.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.51732</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.52300</td>\n",
       "      <td>13.31</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.82</td>\n",
       "      <td>71.99</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.51811</td>\n",
       "      <td>12.96</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.43</td>\n",
       "      <td>72.92</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.51797</td>\n",
       "      <td>12.74</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.35</td>\n",
       "      <td>72.96</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.51594</td>\n",
       "      <td>13.09</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.55</td>\n",
       "      <td>72.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K     Ca    Ba    Fe  Type\n",
       "150  1.51665  13.14  3.45  1.76  72.48  0.60   8.38  0.00  0.17     3\n",
       "123  1.51707  13.48  3.48  1.71  72.52  0.62   7.99  0.00  0.00     2\n",
       "205  1.51732  14.95  0.00  1.80  72.99  0.00   8.61  1.55  0.00     7\n",
       "69   1.52300  13.31  3.58  0.82  71.99  0.12  10.17  0.00  0.03     1\n",
       "99   1.51811  12.96  2.96  1.43  72.92  0.60   8.79  0.14  0.00     2\n",
       "37   1.51797  12.74  3.48  1.35  72.96  0.64   8.68  0.00  0.00     1\n",
       "83   1.51594  13.09  3.52  1.55  72.87  0.68   8.05  0.00  0.09     2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "def read(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "df = read('Data Files/glass.csv')\n",
    "rand = np.random.permutation(df.index)\n",
    "df = df.loc[rand]\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 2: Data Cleaning\n",
    "\n",
    "### Instructions\n",
    "\n",
    "        ● Use the DataFrame.replace() method to replace any and all of the non-null values with the\n",
    "        numpy.nan missing value.\n",
    "        \n",
    "        ● Determine which columns need to be converted to numeric types. You can use either the\n",
    "        DataFrame.astype() or the Series.astype() methods to convert column types.\n",
    "        \n",
    "        ● Return the number of rows that have a missing value for the normalized-losses column.\n",
    "        This can be determined using Dataframe.info(). Determine how you should handle this column. \n",
    "        You could:\n",
    "        \n",
    "            ○ Replace the missing values using the average values from that column.\n",
    "\n",
    "            ○ Drop the rows entirely (especially if other columns in those rows have missing\n",
    "            values).\n",
    "\n",
    "            ○ Drop the column entirely.\n",
    "\n",
    "        ● Explore the missing value counts for the other numeric columns and handle any\n",
    "        missing values.\n",
    "        \n",
    "        ● Of the columns we decided to keep, normalize the numeric ones so all values range\n",
    "        from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 214 entries, 179 to 38\n",
      "Data columns (total 10 columns):\n",
      "RI      214 non-null float64\n",
      "Na      214 non-null float64\n",
      "Mg      214 non-null float64\n",
      "Al      214 non-null float64\n",
      "Si      214 non-null float64\n",
      "K       214 non-null float64\n",
      "Ca      214 non-null float64\n",
      "Ba      214 non-null float64\n",
      "Fe      214 non-null float64\n",
      "Type    214 non-null int64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 18.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.564866</td>\n",
       "      <td>-0.328006</td>\n",
       "      <td>0.530687</td>\n",
       "      <td>0.631109</td>\n",
       "      <td>-0.220690</td>\n",
       "      <td>0.157843</td>\n",
       "      <td>-0.405411</td>\n",
       "      <td>-0.352051</td>\n",
       "      <td>1.159608</td>\n",
       "      <td>0.104398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-0.426565</td>\n",
       "      <td>0.088353</td>\n",
       "      <td>0.551486</td>\n",
       "      <td>0.530962</td>\n",
       "      <td>-0.169047</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>-0.679451</td>\n",
       "      <td>-0.352051</td>\n",
       "      <td>-0.585079</td>\n",
       "      <td>-0.370946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.344243</td>\n",
       "      <td>1.888492</td>\n",
       "      <td>-1.861147</td>\n",
       "      <td>0.711226</td>\n",
       "      <td>0.437760</td>\n",
       "      <td>-0.762132</td>\n",
       "      <td>-0.243798</td>\n",
       "      <td>2.765286</td>\n",
       "      <td>-0.585079</td>\n",
       "      <td>2.005775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.526107</td>\n",
       "      <td>-0.119826</td>\n",
       "      <td>0.620814</td>\n",
       "      <td>-1.251641</td>\n",
       "      <td>-0.853319</td>\n",
       "      <td>-0.578137</td>\n",
       "      <td>0.852359</td>\n",
       "      <td>-0.352051</td>\n",
       "      <td>-0.277193</td>\n",
       "      <td>-0.846290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.084107</td>\n",
       "      <td>-0.548431</td>\n",
       "      <td>0.190977</td>\n",
       "      <td>-0.029857</td>\n",
       "      <td>0.347385</td>\n",
       "      <td>0.157843</td>\n",
       "      <td>-0.117319</td>\n",
       "      <td>-0.070485</td>\n",
       "      <td>-0.585079</td>\n",
       "      <td>-0.370946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RI        Na        Mg        Al        Si         K        Ca  \\\n",
       "150 -0.564866 -0.328006  0.530687  0.631109 -0.220690  0.157843 -0.405411   \n",
       "123 -0.426565  0.088353  0.551486  0.530962 -0.169047  0.188509 -0.679451   \n",
       "205 -0.344243  1.888492 -1.861147  0.711226  0.437760 -0.762132 -0.243798   \n",
       "69   1.526107 -0.119826  0.620814 -1.251641 -0.853319 -0.578137  0.852359   \n",
       "99  -0.084107 -0.548431  0.190977 -0.029857  0.347385  0.157843 -0.117319   \n",
       "\n",
       "           Ba        Fe      Type  \n",
       "150 -0.352051  1.159608  0.104398  \n",
       "123 -0.352051 -0.585079 -0.370946  \n",
       "205  2.765286 -0.585079  2.005775  \n",
       "69  -0.352051 -0.277193 -0.846290  \n",
       "99  -0.070485 -0.585079 -0.370946  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_listings = (df - df.mean()) / (df.std())\n",
    "df_norm = normalized_listings\n",
    "columns = df_norm.columns\n",
    "columns = columns.to_list()\n",
    "columns.pop()\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 3: Univariate Model\n",
    "\n",
    "### Instructions\n",
    "        ● Create a function, named knn_train_test() that consists of the training and simple\n",
    "        validation process. This function should have 3 parameters -- training column name,\n",
    "        target column name, and the dataframe object.\n",
    "\n",
    "            ○ This function should split the data set into a training and test set.\n",
    "\n",
    "            ○ Then, it should instantiate the KNeighborsRegressor class, fit the model on the\n",
    "            training set, and make predictions on the test set.\n",
    "\n",
    "            ○ Finally, it should calculate the RMSE and return that value.\n",
    "\n",
    "        ● Use this function to train and test univariate models(model having only one column for prediction) \n",
    "        using the different numeric columns in the data set. Which column performed the best using the default\n",
    "        k value?\n",
    "        \n",
    "        ● Modify the knn_train_test() function to accept a parameter for the k value.\n",
    "        \n",
    "            ○ Update the function logic to use this parameter.\n",
    "\n",
    "            ○ For each numeric column, create, train, and test a univariate model using the\n",
    "            following k values (1, 3, 5, 7, and 9) and print the rmse values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mg': 0.6367516757498686,\n",
       " 'K': 0.7803298680277897,\n",
       " 'Ba': 0.7865007005712804,\n",
       " 'Al': 0.7983045070995736,\n",
       " 'Na': 0.8373692405859716,\n",
       " 'RI': 0.9278632133238232,\n",
       " 'Ca': 1.0183652124861269,\n",
       " 'Si': 1.1147338662653834,\n",
       " 'Fe': 1.1422991059429923}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_values = []\n",
    "def knn_train_test(training_col,target_col,dataframe):\n",
    "    train_df, test_df = train_test_split(dataframe, test_size= 0.2, random_state = 0)\n",
    "    knn = KNeighborsRegressor(algorithm='brute')\n",
    "    train_features = train_df[[training_col]]\n",
    "    train_target = train_df[[target_col]]\n",
    "    knn.fit(train_features, train_target)\n",
    "    predictions = knn.predict(test_df[[training_col]])\n",
    "    rmse_value = np.sqrt(mean_squared_error(test_df[[target_col]], predictions))\n",
    "    return rmse_value\n",
    "for col in columns:\n",
    "    rmse_values.append(knn_train_test(col,'Type',df_norm)) \n",
    "       \n",
    "dictionary = dict(zip(columns, rmse_values))    \n",
    "tups = sorted(dictionary.items(), key= operator.itemgetter(1))    \n",
    "dictionary = dict(tups)\n",
    "best_features = list(dictionary.keys())\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(training_col,target_col,dataframe,k):\n",
    "    train_df, test_df = train_test_split(dataframe, test_size= 0.2, random_state = 0)\n",
    "    knn = KNeighborsRegressor(n_neighbors = k,algorithm='brute')\n",
    "    train_features = train_df[[training_col]]\n",
    "    train_target = train_df[[target_col]]\n",
    "    knn.fit(train_features, train_target)\n",
    "    predictions = knn.predict(test_df[[training_col]])\n",
    "    rmse_value = np.sqrt(mean_squared_error(test_df[target_col], predictions))\n",
    "    return rmse_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1  as k value: \n",
      "\n",
      "1.0070537282009477\n",
      "0.8758917081092925\n",
      "0.9725461963188082\n",
      "1.092161632325086\n",
      "1.1346372290386095\n",
      "0.9616794173026916\n",
      "1.2471533069273262\n",
      "1.4333833841143229\n",
      "1.2020992716283645\n",
      "\n",
      "\n",
      "For 3  as k value: \n",
      "\n",
      "1.056566110064784\n",
      "0.8028552822207828\n",
      "0.7648681788233993\n",
      "0.8587255951280476\n",
      "1.2096041431234006\n",
      "0.8422497123660158\n",
      "1.0038599502252887\n",
      "0.7451487733131077\n",
      "1.027145123565813\n",
      "\n",
      "\n",
      "For 5  as k value: \n",
      "\n",
      "0.9278632133238232\n",
      "0.8373692405859716\n",
      "0.6367516757498686\n",
      "0.7983045070995736\n",
      "1.1147338662653834\n",
      "0.7803298680277897\n",
      "1.0183652124861269\n",
      "0.7865007005712804\n",
      "1.1422991059429923\n",
      "\n",
      "\n",
      "For 7  as k value: \n",
      "\n",
      "0.8989128224112746\n",
      "0.7274774328588396\n",
      "0.67024121030722\n",
      "0.8133609769625255\n",
      "1.0726938928299268\n",
      "0.7507643212365365\n",
      "0.9540664686441016\n",
      "0.7583677315674198\n",
      "0.9161648258837556\n",
      "\n",
      "\n",
      "For 9  as k value: \n",
      "\n",
      "0.8806559382362935\n",
      "0.7306870245367056\n",
      "0.7048377540609446\n",
      "0.8206764854619149\n",
      "1.0289435636240523\n",
      "0.7764427627339476\n",
      "0.9069304397341443\n",
      "0.7642317961698936\n",
      "0.8389311730826401\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_list  = [1,3,5,7,9]\n",
    "for i in k_list:\n",
    "    print('For',i,' as k value: \\n')\n",
    "    for col in columns:\n",
    "        print(knn_train_test(col,'Type',df_norm,i))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 4: Multivariate Model\n",
    "\n",
    "### Instructions\n",
    "    ● Modify the knn_train_test() function to accept a list of column names (instead of just\n",
    "    one column name as a string). Modify the rest of the function logic to use this parameter:\n",
    "    \n",
    "        ○ Instead of using just a single column for train and test, use all of the columns of\n",
    "        the dataframe except for the target column.\n",
    "\n",
    "        ○ Use the default k value from scikit-learn for this step(default value is 5).\n",
    "\n",
    "    ● Use the best 2 features from the previous step to train and test a multivariate k-nearest\n",
    "    neighbors model using the default k value.\n",
    "    \n",
    "    ● Use the best 3 features from the previous step to train and test a multivariate k-nearest\n",
    "    neighbors model using the default k value.\n",
    "    \n",
    "    ● Use the best 4 features from the previous step to train and test a multivariate k-nearest\n",
    "    neighbors model using the default k value.\n",
    "    \n",
    "    ● Use the best 5 features from the previous step to train and test a multivariate k-nearest\n",
    "    neighbors model using the default k value.\n",
    "    \n",
    "    ● Display all of the RMSE values from the above steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features:  0.48670514897600603\n",
      "Best 2 Features:  0.5650447832668334\n",
      "Best 3 Features:  0.5558564508620003\n",
      "Best 4 Features:  0.5432347415620109\n",
      "Best 5 Features:  0.4858406631266415\n"
     ]
    }
   ],
   "source": [
    "def knn_train_test(training_col,target_col,dataframe):\n",
    "    train_df, test_df = train_test_split(dataframe, test_size= 0.2, random_state = 0)\n",
    "    knn = KNeighborsRegressor(algorithm='brute')\n",
    "    train_features = train_df[training_col]\n",
    "    train_target = train_df[[target_col]]\n",
    "    knn.fit(train_features, train_target)\n",
    "    predictions = knn.predict(test_df[training_col])\n",
    "    rmse_value = np.sqrt(mean_squared_error(test_df[target_col], predictions))\n",
    "    return rmse_value\n",
    "\n",
    "print('All Features: ',knn_train_test(columns,'Type',df_norm))\n",
    "print('Best 2 Features: ',knn_train_test(best_features[:2],'Type',df_norm))\n",
    "print('Best 3 Features: ',knn_train_test(best_features[:3],'Type',df_norm))\n",
    "print('Best 4 Features: ',knn_train_test(best_features[:4],'Type',df_norm))\n",
    "print('Best 5 Features: ',knn_train_test(best_features[:5],'Type',df_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 5: Hyperparameter Tuning\n",
    "\n",
    "### Instructions\n",
    "    ● For the best model from the last step, vary the hyperparameter value from 1 to 25 and plot the\n",
    "    resulting RMSE values.\n",
    "    \n",
    "    ● Observe which k value is optimal for the model(least root mean squared error value for k is the optimal value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_values = []\n",
    "def knn_train_test(training_col,target_col,dataframe,i):\n",
    "    for i in range (1,i+1):\n",
    "        train_df, test_df = train_test_split(dataframe, test_size= 0.2, random_state = 0)\n",
    "        knn = KNeighborsRegressor(n_neighbors = i,algorithm='brute')\n",
    "        train_features = train_df[training_col]\n",
    "        train_target = train_df[[target_col]]\n",
    "        knn.fit(train_features, train_target)\n",
    "        predictions = knn.predict(test_df[training_col])\n",
    "        rmse_values.append(np.sqrt(mean_squared_error(test_df[target_col], predictions))) \n",
    "    return rmse_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'rmse_values')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "li = knn_train_test(best_features[:5],'Type',df_norm,25)\n",
    "plt.plot(li, '-ok')\n",
    "plt.xlabel('hyperparameter value')\n",
    "plt.ylabel('rmse_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 6: K-fold cross validation\n",
    "\n",
    "### Instructions\n",
    "\n",
    "    ● Modify the knn_train_test() function to use k-fold cross validation instead of\n",
    "    test/train validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmses:  [0.4648368399259295, 0.5253350115282207, 0.8194819911515256, 0.5516813006225434, 0.44470429203961326] \n",
      " average rmse:  0.5612078870535664\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "chunks = np.array_split(df_norm, num_folds)\n",
    "for i in range(0,len(chunks)):\n",
    "    chunks[i]['Fold'] = i\n",
    "result = pd.concat(chunks)\n",
    "def train_and_validate(result,folds):\n",
    "    rmses = []\n",
    "    for i in range (0,folds):\n",
    "        model = KNeighborsRegressor()\n",
    "        train_iteration_one = result[result[\"Fold\"] != i]\n",
    "        test_iteration_one = result[result[\"Fold\"] == i].copy()\n",
    "        model.fit(train_iteration_one[best_features[:4]], train_iteration_one[\"Type\"])\n",
    "        test_iteration_one[\"predicted_Type\"] = model.predict(test_iteration_one[best_features[:4]])\n",
    "        iteration_one_mse = mean_squared_error(test_iteration_one[\"Type\"],test_iteration_one[\"predicted_Type\"])\n",
    "        rmses.append(iteration_one_mse ** (1/2))\n",
    "    return rmses\n",
    "rmses = train_and_validate(result,num_folds)\n",
    "avg_rmse = np.mean(rmses)\n",
    "print('rmses: ',rmses,'\\n','average rmse: ',avg_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
